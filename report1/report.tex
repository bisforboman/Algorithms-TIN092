\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{listings}
\usepackage{color}
\usepackage{listings}

\title{Algorithms, assignment - part 1 by Group 26}
\author{Arash Rouhani (rarash@student.chalmers.se) - 901117-1213\\
        Jakob Boman (bisforboman@gmail.com) - 901014-1357}
	

\begin{document}

\maketitle

\section{How our algorithm works}
We generate a list of all possible paths, starting from node 1. For each path we calculate the cost using the given latency-formula, and just pick the cheapest path as our answer.

\section{Pseudocode}
Graph representation: A complete weighted probabilistic graph $G = (EC, D)$, where $EC$ is a
matrix such that $c = EC_{uv}$ is the cost for traversing from node $u$ to $v$.
$D$ is a list, so that $p = D_u$ is the probability of node $u$ being the broken lift.
A matrix is a list of lists.

Below we have annotated the complexity of permutations at
each instruction.
We define the complexity of permutations for $O(Perms(n))$,
$n$ being the length of the argument list.

Yield means adding an element to the end result.

\begin{lstlisting}[mathescape]
    permutations : [a] -> [[a]]
    permutations [] = [[]] O(1)
    permutations xs =
        forEach (x $\in$ xs) O(n)
            ys := xs $\setminus$ x O(n)
            perms := permutations(ys) O(Perms(n-1))
            forEach (zs $\in$ perms) O(n!)
                yield (x:zs) O(1)

    generatePaths : Int -> Paths
    generatePaths n =
        permutations of [1..n] that starts with 1

    pathCost : Graph -> Path -> Double
    pathCost (edgeMatrix, costs) path = 
        $sum (accumulativeEdgeCosts_i * D_i) (i = 1..n)$
      where
        $edgeCosts_i = edgeMatrix_{(path_i, path_{i+1}} (i = 1..n-1)$
        $accumulativeEdgeCosts_i = sum of edgeCosts_j (1 <= j <= i-1) (i = 1..n) $
    
    bestPathAndCost : Graph -> (Double, Path)
    bestPathAndCost G = 
        minimum (pathCost G p, p) (p $\in$ generatePaths n))

\end{lstlisting}

\section{Correctness}
The task is to find the hamlitonian path with minimal expected latency.
We claim that we try all hamiltonian paths, so we must show that
1: All our paths are indeed hamiltonian
2: All such paths are generated

We have $n$ nodes called $1..n$, our path $P$ is a permutation of all nodes $1..n$.
We interpret the $P_i$ as the $i$th node we have visited.
That means we visit $n$ nodes, and since the elements in $P$ are unique.
We are visiting each node exactly once, thus, $P$ is hamiltonian.

Conversely, the only way for a path $P$ to be hamiltonian is to be a permutation of $1..n$.
Otherwise not $n$ nodes are not visited, or not visited at least once.
Therefore generating all permutations means generating all hamiltonian paths.

A small adjustment has to be done since we always start from node $1$.
This is represented by $P_1 = 1$, where $1$ is the first node, and $P_1$ is
the first element in $P$.

How does this relate to the pseudocode? $generatePaths$ will generate
all paths starting from node 1 (we concluded that is all interesting
hamiltonian paths). $bestPathAndCost$ Simply picks the best
of those paths. Thus that is the answer. It should be noted that
$pathCost$ and $permutations$ are helpfunctions for
$bestPathAndCost$ and $generatePaths$ respectively.

\section{Complexity}
The program starts at the expression $bestPathAndCost G$.
$bestPathAndCost$ is clearly
O(<complexity of $generatePaths$>$*$<elements in $generatePaths n$>$+$ $generatePaths n$)

$pathCost$ seem to have the complexity O($n^2$) as of the loop $(1 <= j <= i-1) (i = 1..n)$.
But is of course easily reduced to O($n$) using an accumulator.

$generatePaths$ generates $(n-1)!$ elements. Minus 1 because of we fix first node to $1$. 
The complexity will be O(n!), as it is O($n$) to create each outputlist.

All in all the program $bestPathAndCost$ has complexity O($n!+n!$) = O($n!$).

Ideally our implementation should have used arrays instead of lists.
This being an easily fixed implementation detail, we ignored it.
So in fact our implementation of expected latency is $O(n^2)$.
In other words we assumed indexing to be unit time operation. 

\section{Performence}

\begin{center}
    \begin{tabular}{ | l | l | p{4cm} | p{5cm} |}
    \hline
    Filename & Time(s) & Property & Interpretation \\ \hline
    inst1 & 0.002 & n=5 & A really small n gives small runtime even for O(n!) complexity\\ \hline
    inst2 & 0.594 & n=10 & Runtime is noticeable. Clearly not polynomial anymore comparing to inst1 \\ \hline
    inst2\_weird\_edgecosts & 0.596 & n=10, high edge costs & Same as inst2. Edgecosts have no effect.
        This is obvious as the complexity is stated to only depend on $n$ \\ \hline
    inst2\_weird\_probs & 0.595 & n=10, unbalanced probabilities & Same as for weird edgecosts, only that probabilities changed \\ \hline
    inst3 & 89.417 & n=12 & Runtime have heavly increased with just a increase of 2 nodes.
        O(n!) suggests new time of $0.594*11*12=78.408$, very much like the actual runtime. 
        This rough calculation highly suggests that the comlpexity is of the kind we stated \\ \hline
    \end{tabular}
\end{center}

If we would draw a cartesian graph, with $n$ and $edgecosts$ as the axises, plotting the runtime,
we would see that $edgecosts$ makes no difference, and that runtime grows enormously for each
discrete increase of $n$.

\section{Appendix}
No external resources was used.

All code, test data and more is available at the project's \href{https://github.com/bisforboman/Algorithms-TIN092}{github page}.

A testrun of our program, we compile the program using ghc.

\begin{lstlisting}
> ghc --make Part1.hs -O2
[1 of 1] Compiling Main             ( Part1.hs, Part1.o )
Linking Part1 ...

> ./Part1 < inst1.txt 
Min. Expected Latency: 29.327094
Path: 1 4 2 3 5

\end{lstlisting}




\end{document}
